#!/usr/bin/env bash
set -euo pipefail
echo "=============================="
echo "üîç Big Data Analytics - Env Check"
echo "=============================="

echo "== Conda =="
if command -v conda >/dev/null 2>&1; then
  conda --version
  conda info --envs | grep '*' || echo "‚ö†Ô∏è  Aucun environnement conda actif"
else
  echo "‚ùå conda non trouv√© (installe Miniconda)"
fi
echo

echo "== Java =="
if command -v java >/dev/null 2>&1; then
  java -version
else
  echo "‚ùå Java non trouv√© (installe OpenJDK 21 : sudo apt install -y openjdk-21-jdk)"
fi
echo

echo "== Python =="
if command -v python >/dev/null 2>&1; then
  python -V
else
  echo "‚ùå Python non trouv√© (conda create -n bda-env python=3.10)"
fi
echo

echo "== PySpark =="
if python -c "import pyspark" >/dev/null 2>&1; then
  python -c "import pyspark; print('PySpark', pyspark.__version__)"
else
  echo "‚ùå PySpark non trouv√© (pip install pyspark findspark)"
fi
echo

echo "== Spark =="
if command -v spark-submit >/dev/null 2>&1; then
  spark-submit --version
else
  echo "‚ö†Ô∏è spark-submit non trouv√© (tu utilises peut-√™tre l‚Äôinstallation pip-only ?)"
fi
echo

echo "== JupyterLab =="
if command -v jupyter >/dev/null 2>&1; then
  jupyter --version
else
  echo "‚ùå JupyterLab non trouv√© (pip install jupyterlab)"
fi
echo

echo "== Spark smoke test =="
python - <<'EOF'
try:
    from pyspark.sql import SparkSession
    spark = SparkSession.builder.appName("bda-env-check").getOrCreate()
    print(f"Spark Version: {spark.version}")
    print("Count:", spark.range(0, 10).count())
    spark.stop()
except Exception as e:
    print("‚ùå Spark test √©chou√© :", e)
EOF

echo
echo "‚úÖ V√©rification termin√©e."
echo "Si tout est vert, ton environnement est pr√™t ! üéâ"
