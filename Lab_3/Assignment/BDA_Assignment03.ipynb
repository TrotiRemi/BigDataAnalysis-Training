{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85d9bfe3",
   "metadata": {},
   "source": [
    "# Big Data Analytics — Assignment 03\n",
    "> Author : Badr TAJINI - Big Data Analytics - ESIEE 2025-2026\n",
    "\n",
    "**Chapter 5 :** Graphs (PageRank/PPR)   \n",
    "**Chapter 6 :** Spam classification (SGD) in PySpark\n",
    "\n",
    "**Tools :** Spark or PySpark.   \n",
    "**Advice:** Keep evidence and reproducibility.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9ca3c4",
   "metadata": {},
   "source": [
    "## 0. Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206af0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write some code here\n",
    "# - create SparkSession('BDA-A03') with UTC timezone\n",
    "# - print Spark/PySpark/Python versions\n",
    "# - set spark.sql.shuffle.partitions for local runs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68f5c57",
   "metadata": {},
   "source": [
    "## 1. Dataset acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a644ac3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write some code here\n",
    "# - ensure data/p2p-Gnutella08-adj.txt exists (convert from SNAP edgelist if needed)\n",
    "# - ensure spam.train.* and spam.test.qrels.txt exist (download + bunzip2)\n",
    "# - quick sanity checks on file sizes and line counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f22d97a",
   "metadata": {},
   "source": [
    "## 2. Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7fdf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write some code here\n",
    "# - parse adjacency-list line 'u v1 v2 ...' to (u, [v1, v2, ...])\n",
    "# - utility for top-k without collect: use takeOrdered on (rank, node) with key\n",
    "# - formatting helpers to save top-20 CSVs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6d3369",
   "metadata": {},
   "source": [
    "## 3. Part A — PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3537321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write some code here\n",
    "# - parameters: alpha=0.85, iterations, partitions\n",
    "# - initialize ranks uniformly; build adjacency RDD partitioned by key\n",
    "# - iterative loop: contributions + missing mass redistribution\n",
    "# - compute top-20 without collect; write outputs/pagerank_top20.csv\n",
    "# - save any DF stage plan to proof/plan_pr.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f4d0ab",
   "metadata": {},
   "source": [
    "## 4. Part A — Multi-Source Personalized PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fafcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write some code here\n",
    "# - parameters: sources list, alpha, iterations, partitions\n",
    "# - init mass 1/|S| on sources; others 0\n",
    "# - on jump and dangling mass, teleport uniformly to S\n",
    "# - use mapPartitions(..., preservesPartitioning=True) when transforming keyed RDDs\n",
    "# - compute top-20 and write outputs/ppr_top20.csv\n",
    "# - save any DF stage plan to proof/plan_ppr.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2378f6a9",
   "metadata": {},
   "source": [
    "## 5. Part B — TrainSpamClassifier (SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22417a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write some code here\n",
    "# - parameters: delta, epochs, shuffle flag, numReducers=1\n",
    "# - read training lines: docid label f1 f2 ...\n",
    "# - emit (0, (docid, isSpam, features)) and groupByKey(1) to a single learner\n",
    "# - implement SGD updates on the reducer side; save model to outputs/model_*/part-00000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500620d9",
   "metadata": {},
   "source": [
    "## 6. Part B — ApplySpamClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2a8f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write some code here\n",
    "# - load model tuple file to dict or broadcast\n",
    "# - score test instances and emit (docid, score, predicted_label)\n",
    "# - write outputs/predictions_*/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627d876a",
   "metadata": {},
   "source": [
    "## 7. Part B — ApplyEnsembleSpamClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f8f35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write some code here\n",
    "# - --method average or vote\n",
    "# - load multiple part-00000 model files; broadcast\n",
    "# - average scores or majority vote; write outputs and a small sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13a7dd7",
   "metadata": {},
   "source": [
    "## 8. Evaluation and shuffle study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1486df5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write some code here\n",
    "# - compute ROC-AUC with Spark ML if desired\n",
    "# - or invoke external compute_spam_metrics if available (optional)\n",
    "# - implement --shuffle: random key + sortBy to permute training before SGD\n",
    "# - run 10 trials on britney; summarize in outputs/metrics.md\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479520c0",
   "metadata": {},
   "source": [
    "## 9. Spark UI evidence\n",
    "Open http://localhost:4040 during runs. Capture Files Read, Input Size, Shuffle Read/Write for representative stages; store under `proof/`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e83751e",
   "metadata": {},
   "source": [
    "## 10. Environment and reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb62573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write some code here\n",
    "# - print Java version, Spark conf of interest, OS info\n",
    "# - save ENV.md with versions + key configs\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
